USE catalog;
SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0;
SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0;
SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';
SET FOREIGN_KEY_CHECKS=0;


truncate `csm_excel_import`;
INSERT INTO `csm_excel_import` VALUES ('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','lettura dati','Lettura dati archivio','Lettura archivi di riferimento (ASIA, Farm register, RACLI, FRAME SBS  a seconda delle unità di rilevazione)','archivio o registro contenente la potenziale popolazione di interesse','input0','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','microdati d\'archivio formattati','dati d\'archivio in formato elaborabile','ouput1','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','selezione unità','Selezione del sottoinsieme di unità appartenenti alla popolazione obiettivo dell’indagine','applicazione metodi di selezione. Tipicamente tramite condizioni di IF utilizzando variabili disponibili nell\'archivio di riferimento','dati in formato elaborabile','output 1','metadati utili alla selzionee delle unità appartentii alla popolazione di indagine (es. classsi ateco, dimensione, ecc)','Metodi di selezione','microdati popolazione da archivio','Lista unità appartenenti alla popolazione obiettivo con potenziali variabili di stratificazzione, localizzazione delle unità, ecc.','output 2','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','lettura dati','lettura dati su \"ASIA eventi\"\"\"\"\"\"\"\" e da indagini precedenti\"\"\"\"\"\"\"','si  tratta di acquisire informazioni sulle trasformazioni delle unità della popolazione di riferimento','archivio o registro con informazioni sugli eventi di trasformazione delle  unità','inpiut 0 bis','metadati di lettura (path, tracciato record, psw, ecc) ','lettura dati','microdati ausiliari','dati in formato elaborabile','output 1 bis','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','integrazione dati','abbinamento lista unità appartenenti alla popolazione con informazioni sulle trasformazioni','le informazioni sulle trasformazioni devono essere correttamente abbinate alle singole unità','lista unità con informazioni sulle trasformazioni ','output 1 + input 0 bis','chiavi di link tra unità della popolazione e unità trasformate ','abbinamento tra fonti di dati','microdatipopolazione arricchita','lista unità aggiornata con informazioni sulle trasformazioni','output 2','metodi di rekord linkage: da merge a relais','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','aggiornamento lista','Aggiornamento della lista per trasformazione unità (cessazioni, fusioni, trasformazioni, ecc)','Si tratta di aggiornare la lista della popolazione utilizzando le regole di evoluzione demografica delle unità gia presenti nella popolazione selezionata. Gli eventi di cui si deve tener conto sono soltamente contenuti in \"ASIA eventi\"\"\"\"\"\"\"\" o riguardano informazioni su singole imprese che hanno subito trasformazioni (suddivisoni, trasformazioni, cessazioni, ecc)\"\"\"\"\"\"\"','lista unità aggiornata con informazioni sulle trasformazioni','output 2','metadati sugli eventi di trasformazione','implementazione regole di trasformazione','microdati  archivio aggiornati','Lista aggiornata delle unità appartenenti alla popolazione obiettivo  ','output 3','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','lettura dati ','lettura dati da fonti con informazioni ausiliarie','acquisizione lista nuove unità non presenti nell\'ouput 3','lista nuove unità','input0 bis','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','microdati ausiliari','microdati formattati','output 1bis','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','aggiornamento lista','aggiunta rekord nuove nate','Si tratta di aggiungere unità “nuove nate” non presenti nell\'ultima versione del registro','Lista unità appartenenti alla popolazione obiettivo aggiornata','ouput 3+output 1 bis','','unione file','microdati popolazione ','Lista aggiornata integrata con le nuove unità','output 4','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','lettura dati ','acquisizione micro dati con informazioni ausiliarie sui fenomeni di interesse e linkabili alla lista della popolazione','In alcuni casi è possibile linkare direttamente alle unità della popolazione selezionata informazioni sui variabili proxy dei fenomeni di interesse provenienenti da altre fonti (tipicamente indagini precedenti o archivi amministrativi). Queste verranno usate per descrivere le distribuzioni (medie e varianze) utili alla definizione del disegno di campionamento','archivio o fonti con variabili proxy delle variabili diinteresse','input 1','Metadati di lettura concernenti le fonti con le variabili proxy (path, tracciato record, psw, ecc)','lettura dati','microdati ausiliari','microdati relativi a tutta o a una parte della popolazione','input 1','metodfi di rekord linkage: da merge a relais','','','Procedure ad hoc SAS o R , relais','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','integrazione dati','abbinamento della lista delle unità della popolazione aggiornatacon informazioni variabili proxy','','','input1+outpu4','','abbinamento tra fonti di dati','microdati popolazioni arricchiti','lista popolazione arricchita','output 5','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','lettura dati','acquisizione micro dati con informazioni ausiliarie NON integrabile a livello micro con lista popolazione (alternativa ai due passi precedetni)','In alcuni casi NON è possibile linkare direttamente alle unità della popolazione selezionata informazioni sui variabili proxy dei fenomeni di interesse provenienenti da altre fonti (tipicamente indagini precedenti o archivi amministrativi). Nondimeno è possibile acquisire informazioni su variabili proxy che potranno essere successivamente connesse alla popolazione di interesse tramite codice di strato','dati da indagini precedenti, dati da registro, dati amministrativi con variabili proxy delle variabili di interesse e con variabili utili alla stratificazione che devono essere presenti anche nella lista di popolazione','input 2','Metadati sulle fonti con informazioni sulla variabilità ','lettura dati','microdati ausiliari','microdati con informazioni ausiliarie','output 5 bis (alternatiivo a output 5)','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','analisi  dati','Individuazione di variabili esplicative dei fenomeni di interesse','Si tratta dell\'analisi delle fonti con le variabili proxy utile a individuare quali tra le varibili acquisite possono essere più utili. Alcune analisi possono essere indirizzate da indicazioni fornite da esperti di settore o da precedenti edizioni dell\'indagine','lista popolazione arricchita o \nlista microdati con informazioni ausiliarie','output 5 o output 5 bis','indicazioni sulle potenziali variabili esplicative','analisi della dipendenza ','identificativo variabili esplicative','lista potenziali varibili di stratificazione','output 6','matrici di corrrelazione, tabelle di contingenza, alberi di regressione, ecc.','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','identificazioni unità influenti','determinazione del take all strato','Serve ad individuare le unità maggiormente significative. Quelle cioè che spiegano una parte rilevante dei fenomeni osservati. Di solto di determina una soglia dimensionale','Lista unità appartenenti alla popolazione obiettivo integrata \ninformazione ausiliaria sui fenomeni di interesse','(output 5 o output 5 bis) + output 6','cv desiderati per dominio','implementazione algoritmo per la definizione eventuali strati take all','identificativo unità','Lista unità con flag delle unità che appartegono al take all stratum','output 7','algoritmo di hidiroglou betelot','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','identificazione unità ininfluenti','determinazione del take none strato','Serve ad individuare le unità che danno un contributo poco rilevante al fenomeno complessivo. Questo passo crea una distorsione trascurabile. Di solito si determina una soglia dimensionale','Lista unità appartenenti alla popolazione obiettivo per la selezione del campione+\ninformazione ausiliaria sui fenomeni di interesse','(output 5 o output 5 bis) + output 6','cv desiderati per dominio','implementazione algoritmo per la definizione eventuali strati take none','identificativo unità','Lista unità con flag delle unità che appartegono al take none stratum','output 8','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','stratificazione','determinazione della stratificazione','si determina la suddivisione delle unità in gruppi ritenuti omogenei rispetto alle variabili proxi ed i parametri che caratterizzano ciascun gruppo.\n','Lista unità appartenenti alla popolazione obiettivo per la selezione del campione+flag concernenti i take all e i take non strata','(output 5  o output 5 bis) + output 7 + output 8','parametri utili alla stratificazione.Es. dimensione minima di strato cv di dominio','Implementazione tecniche di raggruppamento delle unità e caratterizzazione dei gruppi: medie e varianze di strato di variabili correlate alle variabili di interesse\n','identificativo di strato com medie e varianze','Lista strati con medie e varianze','ouput 9','metodi di \"clusterizzazzione\"\"\"\"\"\"\"\" , algoritmi evolutivi,  kmeans, regenesees, summary, ecc\"\"\"\"\"\"\"','','','Procedure ad hoc SAS o R\nLibreria SamplingStrata,  ecc','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','aggiornamento lista','integrazione popolazione aggiornata con lista strati (nel caso si sia usato l\'output 5 bis)','ad ogni unità della lista si abbina il suo codice strato','lista popolazione aggiornata e lista strati','output 4 + output 10','','abbinamento per codice di strato','popolazione stratificata ','lista strati con parametri utili all\'allocazzione','output 10 bis','','','','','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','definizione del disegno di campionamento (stratificato)','determinazione numerosità campionaria','allocazione delle unità','implementazione algoritmo di allocazione (es: proporzionale, ottima, Bethel, multiway, …)','dati da indagiini precedenti, dati da registro, da amministtrativi con variabili proxy delle variabili di interesse e con variabili utili alla stratificazione','output 10 o output 10 bis','cv desiderati per dominio','implementazione algoritmo di allocazione (es: proporzionale, ottima, Bethel, multiway, …)','lista strati con dimensione campionaria','lista strati con dimesnione campionaria','output 11','Bethel, proporzional, Neyman, ecc','','','Mauss-R, R2Beat, Multiway, Sampling Strata','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione delle unità','identificazione unità campionarie','Selezione delle unità','in questo passo si indivisuano le unità che faranno concretamente parte del campione ','Output algoritmo di allocazione e lista popolazione arricchita','output 11 + output 6','Informazioni sulle unità già selezionate da altre indagini','metodo di selezione','campione indagine','lista unità campionarie con codsiuce strato e peso campionario iniziale','output 12','selezione sistematica, seuenziale, poisson, coordinata, ecc.','FS4, R2BEAT, SAS macro Cube, R-BalancedSampling','','Procedure ad hoc SAS (Proc survey select)  o R','Disegno di campionamento Indagini_economiche','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','lettura dati','Lettura dati archivi di riferimento ','Lettura archivio o registro contenente la potenziale popolazione di interesse, comuni, scuole o altro a seconda delle unità di rilevazione e variabili di stratificazione','archivio di riferimento','input 0','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','microdati archivio formattai','dati archivio in formato elaborabile','ouput1','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Definizione della popolazione obiettivo dell’indagine','selezione unità','Selezione del sottoinsieme di unità appartenenti alla popolazione obiettivo dell’indagine','applicazione metodi di selezione. Tipicamente tramite condizioni di IF utilizzando variabili disponibili nell\'archivio di riferimento','dati archivio in formato elaborabile','ouput 1','condizioni di appartenenza alla popolazione','metodi di selezione (if)','microdati popolazione da archivio','Lista unità appartenenti alla popolazione obiettivo','output 2','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','analisi dati','Individuazione variabili esplicative dei fenomeni di interesse','Individuazione di variabili su cui basare l\'allocazione (stime di precedenti indagini, frequenze tipiche)','Lista unità appartenenti alla popolazione obiettivo','ouput 2','Fonti ausiliarie relative a variabili correlate alle variabili di interesse','analisi della dipendenza','identificativo variabili esplicative','Lista potenziali variabili di stratifcazione','ouput 3','matrici di corrrelazione, tabelle di contingenza, alberi di regressione, ecc.','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','stratificazione','Definizione dello strato e dei domini pianificati','si determina la suddivisione delle unità in gruppi ritenuti omogenei rispetto alle variabili proxi e si determinano i parametri che caratterizzano ciascun gruppo.','Lista unità appartenenti alla popolazione obiettivo per la selezione del campione','','parametri utili alla stratificazione.Es. dimensione minima di strato cv di dominio','Implementazione tecniche di raggruppamento delle unità e caratterizzazione dei gruppi: medie e varianze di strato di variabili correlate alle variabili di interesse','identificativo di strato con medi e varianze','lista strati con parametri utili all\'allocazione','','metodi di \"clusterizzazzione\"\"\"\"\"\"\"\" , algoritmi evolutivi,  kmeans, regenesees, summary, ecc\"\"\"\"\"\"\"','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','aggiornamento lista','integrazione popolazione aggiornata con lista strati','ad ogni unità della lista si abbina il suo codice strato','lista popolazione aggiornata e lista strati','','','abbinamento per codice di strato','popolazione stratificata ','lista strati con parametri utili all\'allocazzione','','','','','','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','determinazione numerosità campionaria','allocazione delle unità','implementazione algoritmo di allocazione (es: proporzionale, ottima, Bethel, multiway, …)','lista strati con parametri utili all\'allocazzione','output 10 o output 10 bis','cv desiderati per dominio','implementazione algoritmo di allocazione (es: proporzionale, ottima, Bethel, multiway, …)','lista strati con dimensione campionaria','lista strati con dimesnione campionaria','output 11','Bethel, proporzional, Neyman, ecc','Mauss-R, R2Beat, Multiway, Sampling Strata','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','selezione unità','Selezione delle unità indagini cross section','selezione semplice: in questo passo si identificano le unità della popolazione che saranno effettivamente incluse nel campione per una indagine cross section','Output algoritmo di allocazione e lista popolazione aggiornata','','Informazioni sulle unità già selezionate da altre indagini','implementazione metodi di selezione','campione selezionato','Campione selezionato','','Selezione probabilistica con probabilità uguali','FS4, R2BEAT, SAS macro Cube, R-BalancedSampling','','Procedure ad hoc SAS (Proc survey select)  o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','selezione unità','selezione per indagini panel','Selezione con metodi di rotazione per indagini panel','Output algoritmo di allocazione e lista popolazione aggiornata e identificativi unità selezionate nelle precedenti occasioni di indagine','','Schema temporale di rilevazione (rotazione)','metodo di selezione dei periodi','campione sezionato','Campione selezionato con attribuzione dei periodi di rilevazione','','Selezione casuale dei periodi di rilevazione della unità','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Calcolo pesi diretti','Calcolo pesi diretti','Calcolo pesi diretti','Calcolo pesi diretti','Campione selezionato','','Probabilità di inclusione ','Calcolo del peso diretto','','Campione selezionato con pesi diretti ','','Calcolo del peso campionario sulla base delle probabilità di inclusione','','','Procedure ad hoc SAS (Proc survey select) o R','Disegno di campionamento Indagini_sociali 1 stadio','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','preparazione lista UPS partendo da lista unità finali','lettura dati','lettura archivio unità finali','Questo passo viene solitamente effettuato esternamente (ad esempio DCRD) piuttosto che da chi è direttamente coinvolto nella predisposizione del disegno dicampionamentop a due stadi','archivio unità finali (famigle, individui, alunni, ecc)','input 0','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','dati formattati','dati in formato elaborabile per i passi successsivi','output 1','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','preparazione lista UPS partendo da lista unità finali','preprazione dati','partizione delle popolazione delle unità finali in sottopolazioni ','serve per individuare gruppi di unità finali in cui applicare eventualmente disegni di campionamento differenti. Ad esempio famiglie con tefono e famiglie senza telefono (non sempre questo passo viene effettuato)','archivio unità finali (famigle, individui, alunni, ecc)','output 1','caratteristiche delle unità finali utili a differenziare i disegni di campionamento','implementazione regole deterministiche (IF THEN)','dati formattati','lista unità finali con flag delle unità da osserevare tramite campinamento a due stadi','output 2','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','preparazione lista UPS partendo da lista unità finali','preprazione lista unità primarie','aggregazione delle unità finali per codice unità primaria','si aggregano le unità finali per codice delle UPS ','archivio unità primarie di selezione','output 2','codici unità primarie','metodi di aggregazione (tablle, summary, ecc)','dati formattati','lista unità primarie (UPS)','output 3a','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','acquisizione lista UPS','lettura dati','lettura lista unità primarie ','questo nel caso tale archivio sia disponibile e non serva passare per i passi precedenti. Tipici esempi: archivio dei comuni con popolazione; archivio scuole con alunni','archivio unità primarie di selezione','input 1','codici unità primarie','lettura dati (read, read.table, ecc)','dati formattati','lista unità primarie (UPS)','output 3b','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','aggiornamento lista','lettura dati','Lettura archivi di riferimento o registri con le trasformazioni delle unità UPS','Acquisizione informazioni su eventi di trasformazione delle UPS lettura e/o acquisizione informazioni su UPS che hanno subito trasformazioni (ad esempio  fusione di comuni)','Lista unità appartenenti alla popolazione obiettivo','output 3a o output 3b','Fonti ausiliarie relative a eventi di trasformazione delle unità',' lettura dati e applicazione regole di trasformazione delle unità ','dati formattati','Lista unità appartenenti alla popolazione obiettivo aggiornata','output 4','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','aggiornamento lista','integrazione dati','abbinamento alla lista delle informazioni sulle trasformazioni','si tratta di linkare le informazioni sulle trasformazioni alla lista iniziale. E\' una operazione che può richiedere attenzione alle regole di continuità delle unità','archivio o registro con informazioni sugli eventi di trasformazione delle UPS','output 5','Fonti ausiliarie relative a eventi di trasformazione delle unità',' lettura dati e applicazione regole di trasformazione delle unità ','dati formattati','Lista unità appartenenti alla popolazione obiettivo aggiornata con trasformazioni','output 6','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','aggiornamento lista','aggiornamento lista','Aggiornamento della lista (eliminazione unità cessate e integrazione con nuove nate)','Si tratta di aggiornare la lista della popolazione UPS utilizzando le regole di evoluzione demografica delle unità gia presenti nella popolazione selezionata. Particolare attenzione deve essere posta alle regole di continuità e quindi ai codici identificativi delle unità nel corso del tempo','Lista unità appartenenti alla popolazione obiettivo aggiornata','output 6','Fonti ausiliarie relative a eventi di trasformazione delle unità',' lettura dati e applicazione regole di trasformazione delle unità ','dati formattati','Lista unità appartenenti alla popolazione obiettivo aggiornata con trasformazioni','output 7','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','aggiornamento lista','lettura dati','lettura archivi di riferimento','Acquisizione informazioni aggiornate su popolazione delle UPS e calcolo della dimensione in termini di unità finali che hanno subito trasformazioni\nqueste informazioni posso arrivare anche da indagini precedenti (ad esempio Forze Lavoro)','Lista unità appartenenti alla popolazione obiettivo aggiornata','output 7','Fonti ausiliarie relative a nuove unità ',' lettura dati e applicazione regole di trasformazione delle unità ','dati formattati','Lista unità appartenenti alla popolazione obiettivo integrata con le nuove unità','output 8','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','aggiornamento lista','integrazione dati','abbinamento delle informazioni sulle unità finali alla lista delle unità UPS','le informazioni sulle trasformazioni devono essere correttamente abbinate alle singole unità','Lista unità appartenenti alla popolazione obiettivo integrata con le nuove unità e le nuove informazioni ausiliarie','output 8','Liste unità precedenti','Link tra archivi','dati formattati','Lista UPS appartenenti alla popolazione obiettivo aggiornata e integrata con le nuove unità e informazioni sulle unità finali','output 9','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','analisi dati','Individuazione di variabili fortemente correlate alle variabili di interesse','Individuazione di variabili su cui basare l\'allocazione (stime di precedenti indagini, frequenze tipiche)','Lista unità appartenenti alla popolazione obiettivo aggiornata e integrata con le nuove unità','output 9','Fonti ausiliarie relative a variabili correlate alle variabili di interesse','Individuazione variabili','dati formattati','Lista unità appartenenti alla popolazione obiettivo per la selezione del campione','output 10','','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','stratificazione 1','determinazione della stratificazione','si stratifcano le unità finali (USS) per caratteristiche delle UPS e si assegnano i domini di stima','Lista unità appartenenti alla popolazione obiettivo per la selezione del campione','output 10','Variabili di stratificazione','Assegnazione dello strato','dati formattati','Lista unità stratificata 1','output 11','Classificazione delle unità della popolazione','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','Aggregazione ','aggrego le unità primarie per la prima stratificazione','contiamo le unità finali per ciascuno strato della stratificazione 1','Lista strati di stratificazione 1','output 11','Variabili di stratificazione','Aggregazione USS in UPS','dati formattati','Lista unità primarie stratificata 1','output 12','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','lettura dati','acquisizione informazioni ausiliarie sugli strati','letture fonti ausiliarie con informazioni proxy sulle variabili di interesse (ad esempio un\'altra indagine) e calcolo caratteristiche a livello della prima stratificazione','Informazioni esterne','input 2','Numerosità, medie e varianze di strato di variabili correlate alle variabili di interesse','Aquisizione stime e varianze','dati formattati','Medie e varianze per strato 1','output 13','Calcolo di medie e varianze','Re-Genesees','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','integrazione dati','abbinamento caratteristiche di stratificazione 1 a lista strati','si tratta di un merge by codice stratificazione 1','Input algoritmo di allocazione','output 13 e input 2','cv desiderati per dominio','Merge','dati formattati','Input algoritmo di allocazione','output 14','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','allocazione','determinole numerosità per strato','Implementazione algoritmo di allocazione sugli strati (es: proporzionale, uniforme, media tra proporzionale e uniforme, ottima, Bethel, multiway, …)','Input algoritmo di allocazione','output 14','cv desiderati per dominio','Algoritmo di allocazione','dati formattati','Output algoritmo di allocazione, lista strati con dimensione campionaria','output 15','Bethel, proporzional, Neyman, ecc','Mauss-R, R2Beat, Multiway, Sampling Strata','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Disegno di campionamento','stratificazione 2','suddivisione in gruppi delle UPS','si suddividono le UPS in strati sulla base della dimensione in termini di unità di popolazione, della allocazione e di parametri di disegno campionario (determinazione AR, NAR)','lista strati con dimensione campionaria','output 12 e output 15','Parametri del disegno a due stadi: interviste per UPS e numero di UPS campione per strato','Stratificazione delle UPS','dati formattati','Lista UPS stratificate secondo stratificazione 2','output 16','','','','','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','selezione ','Selezione UPS','Selezione delle UPS, con o senza rotazione e/o coordinamento','UPS statificate 2','output 16','Informazioni sulle unità già selezionate da altre indagini','Selezione con probabilità uguali o proporzionali alla dimensione ','dati formattati','Campione UPS selezionato','output 17','Selezione probabilistica con probabilità uguali','FS4, R2BEAT, SAS macro Cube, R-BalancedSampling','','Procedure ad hoc SAS (Proc survey select)  o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','assegnazione','calcolo del numero unità finali campionarie per UPS selezionate','Definizione del numero di unità finali campione per UPS','Campione UPS selezionato','output 17','Parametri del disegno a due stadi: interviste per UPS e numero di UPS campione per strato','Calcolo numero di unità campione finali per UPS ','dati formattati','Campione UPS selezionato con campione SSU','output 18','Applicazione del criterio dell\'autoponderanza','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','suddivisione temporale delle interviste','','Stratificazione temporale delle unità finali, assegnazione dei periodi di rilevazione per i UPS','Campione selezionato','output 18','Schema temporale di rilevazione','Metodo di selezione dei periodi','dati formattati','Campione selezionato con attribuzione dei periodi di rilevazione','output 19','Selezione casuale dei periodi di rilevazione della unità','','','Procedure ad hoc SAS o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('Possibili modalità: 2.4. Design frame and sample oppure 4.1. Create frame and select sample','Selezione','Calcolo pesi diretti','Calcolo pesi diretti','Calcolo pesi diretti','Campione selezionato','output 19','Probabilità di inclusione ','Calcolo del peso diretto','dati formattati','Campione selezionato con pesi diretti ','output 20','Calcolo del peso campionario sulla base delle probabilità di inclusione','','','Procedure ad hoc SAS (Proc survey select) o R','Disegno di campionamento Indagini_sociali 2 stadi','','',24),('4.1. create frame and select sample','Lettura e preparazione dati indagine','lettura dati','lettura dati grezzi indagine di riferimento','lettura dati grezzi indagine di riferimento.','dati indagine grezzi ','input0','metadati di lettura  (path, psw, tracciato record, ecc.)','lettura dati (read , read.table, ecc.)','microdati indagine formattati','dati indagine in  formato elaborabile per i passi successivi','output 1','metodi non statistici','','','','Controllo e correzione valori ed unità errate','','',41),('4.1. create frame and select sample','Lettura e preparazione dati indagine','lettura dati','lettura dati di fonti ausiliarie','lettura dati ausiliari (archivi, indagini precedenti, ecc.)','dati fonti ausiliarie','input1','metadati di lettura  (path, psw, tracciato record, ecc.)','lettura dati (read , read.table, ecc.)','microdati  ausiliari','dati micro con informazioni ausiliarie in formato elaborabile per i passi successivi','output 2','metodi non statistici','','','','Controllo e correzione valori ed unità errate','','',41),('4.1. create frame and select sample','Lettura e preparazione dati indagine','integrazione dati','abbinamento dati grezzi indagine e dati ausiliari','Qualora siano disponibili fonti ausiliarie con dati micro, questi vengono linkati con i dati di indagine','dati indagine +\ndati micro con informazioni ausiliarie','ouput1 + output2','chiavi di link tra dati indagine e fonti ausiliarie','abbinamento tra fonti di dati','microdati indagine integrati','dati indagine arricchita con informazioni ausiliarie','output 3','metodi di record linkage: merge, relais, etc','','','','Controllo e correzione valori ed unità errate','','',41),('4.1. create frame and select sample','Lettura e preparazione dati indagine','aggiornamento unità rispondenti','aggiornamento del flag di appartenenza alla popolazione di riferimento per le unità rispondenti',' analisi del profilo dei rispondenti per controllo e individuazione delle unità eleggibili tra le rispondenti','dati indagine eventualmente arricchita con informazioni ausiliarie','output 1 o output 3','condizioni di eleggibilità nella popolazione di riferimento','implementazione regoledi eleggibilità','microdati indagine aggiornati','dataset delle unità eleggibili','output 4','regole deterministiche di identificazione','','','Sas, R, SQL','Controllo e correzione valori ed unità errate','','Review, Selection',41),('5.3 Review & Validate','controllo e correzione errori sistematici',' identificazione unità errate','Controllo dei dati per l\'individuazione delle unità affette da errori sistematici','esempi tipici di errori sistematici sono quelli che concernono l\'errata interpretazione dell\'unità di misura da utilizzare, errori di filtro/percorso del questionario elettronico, ecc','dataset delle unità eleggibili','output 4','fonti ausiliarie, \nregole di (in)compatibilità:\n- regole formali\n- regole sostanziali','Analisi delle distribuzioni e dellle relazioni tra variabili ','identificativo variabili per unità','dataset con flag identificativo delle unità e delle variabili su cui si ritiene vi sia un errore sistematico','output 5','analisi grafiche: scatter plot, qq-plot, \nanalisi dei gruppi: cluster analysis, analisi delle classi latenti, \nanalisi delle distribuzioni univariate e multivariate,','','','Sas, R, SQL','Controllo e correzione valori ed unità errate','','Review, Selection',53),('\n5.4 Edit & Impute','controllo e correzione errori sistematici','correzione dati','Correzione degli errori sistematici (inclusi eventuali valori mancanti)','','dataset delle unità eleggibili con identificativo delle unità-variabili affette da errori sistematici','output 5','supporto tematico alla determinazione delle regole di correzione deterministica degli errori sistematici','implementazione della condizione di errore e relativa azione di correzione (if then)','dati indagine corretti','dataset  corretto con flag di imputazione','output 6','regole deterministiche di correzione','','','Sas, R, SQL','Controllo e correzione valori ed unità errate','','Treatment',53),('5.3 Review & Validate','controllo e correzione degli errori influenti e/o anomali','analisi dati','Controllo dei dati per l\'individuazione delle unità affette da errori influenti e/o valori anomali','In questo passo si analizzano i livelli delle stime ','dataset corretto con flag di imputazione per errore sistematico','output 6','livelli attesi delle stime','Individuazione errori anomali e/o influenti','report','report su distribuzione delle variabili e parametri modelli (tipicamente di regressione)','output 7','analisi grafiche: scatter plot, qq-plot, ecc.\nanalisi delle distribuzioni, \nanalisi longitudinali, funzione score, metodo di Hidiroglou-Berthelot, modelli mistura a classi latenti (modelli di contaminazione)','AGAIN (solo per specifiche indagini)','','Sas (Banff), R (SeleMix)','Controllo e correzione valori ed unità errate','','Review',53),('5.3 Review & Validate','controllo e correzione degli errori influenti e/o anomali',' identificazione unità errate','Identificazione delle  unità influenti e/o anomale','In questo passo si identificano le unità che manifestano potenziali errori influenti (di impatto significativo) sulle stime di interesse e i valori anomali. Tali unità non necessariamente risulteranno errate.','dataset  corretto con flag di imputazione per  errore sistematico','output 6','report su distribuzione delle variabili e parametri modelli (tipicamente di regressione)\noutput 7','Individuazione errori anomali e/o influenti','identificativo variabili per unità ','dataset con flag identificativo delle unità influenti e/o anomale','output 8','determinazione valori soglia: metodo di Hidiroglou-Berthelot, metodo dei quartili, modelli mistura a classi latenti (modelli di contaminazione)','AGAIN (solo per specifiche indagini)','','Sas (Banff), R (SeleMix)','Controllo e correzione valori ed unità errate','','Selection',53),('5.4 Edit & Impute','controllo e correzione degli errori influenti e/o anomali','correzione dati','Correzione delle unità influenti e/o anomale','ricontatto delle unità critiche, confronto con fonti ausiliarie e/o dati storici','dataset  corretto con flag di imputazione per errore sistematico e flag identificativo delle potenziali unità influenti e dei valori anomali','output 8','conoscenza del fenomeno, fonti ausiliarie, supporto da parte degli esperti del fenomeno per la correzione degli errori influenti (idealmente le unità critiche  vengono inviate ai tematici per la loro correzione)','correzione interattiva errori influenti; correzione valori anomali errati','dati indagine corretti','dataset corretto da errori sistematici e influenti e/o anomali con relativi flag di correzione ','output 9','correzione interattiva, ricontatto delle unità critiche, correzione automatica valori influenti/anomali errati (regressione, donatore, etc.)','AGAIN (solo per specifiche indagini); applicazione sviluppata per il Censimento della popolazione nel 2018 (Cuccia, Bianchi)','','Sas, R, SQL','Controllo e correzione valori ed unità errate','','Treatment',54),('5.3 Review & Validate','controllo e correzione errori casuali','identificazione unità errate','Controllo dei dati per l\'individuazione delle unità affette da errori casuali non influenti','individuazione di unità che violano almento una regola di (in)compatibilità','dataset corretto da eventuali errori sistematici e da  errori influenti e/o anomali','output 9','regole di (in)compatibilità:\n- regole formali\n- regole sostanziali','implementazione delle regole di (in)compatibilità','identificativo variabili per unità ','dataset con flag identificativo delle unità-variabili potenzialmente errate;\nReport con misure di qualità','output 10 + report','regole di (in)compatibilità','Concord-SCIA','','Sas (Banff), R, SQL','Controllo e correzione valori ed unità errate','','Review',53),('5.3 Review & Validate','controllo e correzione errori casuali','identificazione variabili errate','Localizzazione errori','individuazione del minimo numero di variabili da trattare tra le unità errate (principio del minimo cambiamento)','dataset con flag in variabili potenzialmente errate','output 10','regole di (in)compatibilità:\n- regole formali\n- regole sostanziali\ncoefficienti di affidabilità delle variabili','set-covering problem (risoluzione di problemi di minima copertura)','identificativo variabili per unità','dataset con flag sulle variabili errate','output 11','metodo di Fellegi-Holt, algoritmo di Chernikova','Concord-SCIA','','Sas (Banff), R, SQL','Controllo e correzione valori ed unità errate','','Selection',54),('5.4 Edit & Impute','controllo e correzione errori casuali','correzione dati','Correzione degli errori casuali non influenti (inclusi eventuali valori mancanti)','l\'output 10 viene suddiviso in due parti sulla base del flag che indica quali siano i record affetti da errore e i record esatti','dataset con flag sulle variabili errate; dataset degli errati; dataset degli esatti','output 11','','imputazione','dati indagine corretti','dataset corretto con flag di correzione ','output 12','\nhot-deck, NIM (nearest neghbour imputation method), regressione, etc.','Concord-SCIA','','Sas (Banff), R, SQL','Controllo e correzione valori ed unità errate','','Treatment',54),('5.4 Edit & Impute','imputazione massiva','correzione dati','imputazione di record con un numero elevato di mancate risposte',' in questo passo sono trattati ad esempio i record in cui le uniche informazioni disponibili sono quelle derivanti da fonte amministrativa. Si tratta quindi di record particolari che solitamente sono trattati a parte, a valle del processo di controllo e correzione.','dataset corretto da errori sistematici, influenti e/o anomali e casuali, comprendendo i record un numero elevato di mancate risposte','output 12','fonti ausiliarie e dati storici','imputazione','dati indagine corretti','dataset corretto con flag di imputazione','output 13','\nhot-deck, NIM (nearest neghbour imputation method), regressione, etc.','','','Sas, R, SQL','Controllo e correzione valori ed unità errate','','Treatment',53),('5.3 Review & Validate','Post editing','macro-editing','Controllo delle stime finali e identificazione degli aggregati sospetti','Analisi delle distribuzioni ottenute sui dati di indagine corretti e confronto con le distribuzioni ottenute da fonti ausuliarie o dati storici, al fine di individuare eventuali aggregati sospetti','dataset corretto','output 13',' tabelle delle stime da analizzare; fonti ausiliarie','analisi longitudinali, confronto con altre fonti; ','report','indicatori di qualità','output 14','intervalli di confidenza,\nanalisi grafiche, \nanalisi delle distribuzioni','','','Sas, R, SQL','Validazione microdati corretti','','Review',53),('5.3 Review & Validate','Post editing','identificazione unità errate','Identificazione delle unità errate che hanno generato gli aggregati sospetti','In questo passo si analizza l\'impatto delle correzioni, dei pesi, della variabilità campionariasu livello delle stime. Si ricercano inoltre ulteriori errori sistematici','dataset corretto','output 13','indicatori di qualità (output 14)','analisi di impatto e di influenza','identificativo variabili per unità','dataset corretto con flag sulle unità che hanno generato gli aggregati sospetti','output 15','intervalli di confidenza, ad hoc','','','Sas, R, SQL','Validazione microdati corretti','','Selection',53),('5.3 Review & Validate','Post editing','micro-editing: identificazione unità errate','Controllo microdati','ri-verifica, sul dataset corretto, di tutte le regole di (in)compatibilità al fine di identificare eventuali record errati (sfuggiti ai controlli precedenti o generati dai vari trattamenti effettuati nei passi precedenti)','dataset corretto','output 13','regole di (in)compatibilità:\n- regole formali\n- regole sostanziali','implementazione delle regole di (in)compatibilità esplicitate nei passi precedenti (if then)','identificativo variabili per unità','dataset con flag identificativo delle unità-variabili potenzialmente errate;\nReport con misure di qualità','output 16','regole di (in)compatibilità','','','Sas, R, SQL','Validazione microdati corretti','','Review',53),('5.7 “Calculate aggregates”','Preparazione dati input','lettura dati','lettura dati di indagine in cui sono già presenti i pesi campionari definitivi','','Dati indagine','input 0','Metadati di lettura(path, tracciato record ecc)','lettura dati indagine (es. read, read.table ecc)','microdati indagine formatttati','Dati indagine in formato elaborabile per i passi successivi','Output1','','','','procedure ad hoc','Stima piccole aree','','dati Forze Lavoro',57),('5.7 “Calculate aggregates”','Preparazione dati input','identificazione ','si assegnano a ciascuna unità i flag di appartenza ai diversi domini di interesse','','Dati indagine formattati ','output 1','Metadati relativi all\'individuazione del dominio','implementazione regole deterministiche: if - then','microdati indagine formatttati con flag di dominio','dati indagine formattati+flag dominio','Output2','','','','procedure ad hoc','Stima piccole aree','','codici territoriali FUA e City',57),('5.7 “Calculate aggregates”','Preparazione dati input','identificazione ','si assegnano a ciascuna unità i flag di appartenenza a una macroarea (opzionale)','','Dati indagine formattati+flag dominio','output 2','Metadati relativi all\'individuazione della macroarea','implementazione regole deterministiche: if - then','microdati indagine formatttati con flag di dominio e macro area','dati indagine formattati+flag dominio+ macroarea','Output3','','','','procedure ad hoc','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Preparazione dati input','aggregazione','calcolo dei totali delle potenziali variabili esplicative del modello','','Dati indagine formattati+flag dominio+macroarea','output3','Indicazione variabili esplicative e del peso finale','Aggregazione pesata ','dataset totali','Dataset di totali noti (una riga per dominio e tante colonne quante sono le variabili esplicative)','Output4','','','','procedure ad hoc','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Preparazione dati input','lettura dati','lettura dati da registro con potenziali variabili esplicative e flag di dominio','','input da registro o archivio ','input 1','Metadati di lettura(path, tracciato record ecc)','lettura dati archivio (es.read, read.table, ecc)','microdati archivio formattati','dati da archivio formattati','Output4','','','','','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Preparazione dati input','aggregazione','si calcolano i totali delle variabili  esplicative per dominio ','','Dati da registro','input_registro','Indicazione del flag di dominio coerente con l\'output2 e varibili esplicative','Aggregazione delle variabili esplicative per il dominio','dataset totali','Dataset di totali noti (una riga per dominio e tante colonne quante sono le variabili esplicative)','Output4','','','','procedure ad hoc','Stima piccole aree','','Totali provenienti da RBI e RTL',57),('5.7 “Calculate aggregates”','Preparazione dati input','lettura dati','si acquisiscono file di totali noti (una riga per dominio e una colonna per ciascuna variabilie esplicativa) preparati esternamente','','File con totali noti','input_noti','Metadati di lettura (path, tracciato record ecc)','lettura file totali noti predisposti esternamente','dataset totali','Dataset di totali noti (una riga per dominio e tante colonne quante sono le variabili esplicative)','Output4','','','','procedure ad hoc','Stima piccole aree','','Totali provenienti da RBI e RTL',57),('5.7 “Calculate aggregates”','Analisi preliminari','Analisi dati','produzione stime dirette e relativi cv, per tutti i domini di una data tipologia (ad esempio stima per ciascun comune) ','','Dati indagine formattati+flag dominio+macroarea','Output3','Indicazione variabili di interesse e del peso','Aggregazione pesata delle variabili di interesse per il dominio con il calcolo dei relativi coefficenti di varaizione','report','Dataset di stime dirette (calibrate) e cv per dominio (una riga per dominio e due colonne per ciasciuna variabile dipende: stima e cv)','Outpu5','Stimatori calibrati','Regenesses','','','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi preliminari','Analisi dati','Valutazione qualità stime dirette','','Dataset di stime dirette (calibrate) e cv per dominio (una riga per dominio e due colonne per ciasciuna variabile dipende: stima e cv)','Output5','Indicazione da parte dei committenti in merito alla qualità minima accettabile dell\'accuratezza delle stime espresse in termini di CV per ciascun dominio (spesso provenienti da regolamenti Europei e linee guida internazionali)','Confronto tra cv indicati dai committenti con cv contenuti in Output5','report','Tabelle che indicano quanti e quali domini non soddisfano i criteri di accettabilità indicati dai committenti','Output6','','Regenesses','','','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi preliminari','Analisi dati','Studio della distribuzione dei domini tra le macroaree','','Dati indagine formattati+flag dominio+macroarea','Output3','Indicazione sul numero minimo di domini per ciascuna macroarea al fine di stimare con accuratezza i parametri del modello','Distribuzione per macroarea dei domini (ad esempio comuni per macroarea proviciale)','report','Tabelle che indicano quante e quali macroaree permettono di stimare con accuratezza i parametri del modello. ','Output7','','','','procedure ad hoc','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi preliminari','aggregazione','ridefinizione delle macroaree nel caso l\'attuale definizione non permetta di stimare i parametri del modello (opzionale)','','Dati indagine formattati+flag dominio+macroarea+indicazioni sulla accuratezza di stima dei parametri del modello per macroarea ','Output3 e Output7','indicazione sulle possibili macroaree che possono essere aggregate nel caso l\'analisi svolta indichi che qualche macroarea non permette di stimare i parametri del modello (opzionale)','Distribuzione per macroarea (ridefinita) dei domini','dataset totali','Tabelle che indicano quante e quali macroaree permettono di stimare con accuratezza i parametri del modello. ','Output7b','','','','procedure ad hoc','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Parametrizzazione del modello','Analisi dati','scelte variabili esplicative per la componente ad effetti fissi del modello (scelta tra quelle di cui si dispone dei totali noti)','','Dati indagine formattati+flag dominio+macroarea','Output3','Metadati relativi all\'individuazione delle variabili esplicative','Regressioni per l\'individuazione del modello con il miglior fitting','report con lista variabili','Tabelle di riassunto dei principali indicatori di model fitting (es AIC, BIC, loglk ecc)','Output8','stepwise regression','','','ad esempio utilizzando libreria R \"MASS\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"','Stima piccole aree','','- Informazioni in ambito occupazionale a livello di individuo in ambito sociale;\n- titolo di studio e la frequenza a corsi di istruzione;\n- le tipologie di pensione (vecchiaia, assistenziale e di invalidità);\n- trattamenti monetari non pensionistici',57),('5.7 “Calculate aggregates”','Parametrizzazione del modello','Analisi dati','scelte variabili esplicative per la componente ad effetti casuali del modello (scelta tra quelle di cui si dispone dei totali noti)','','Dati indagine formattati+flag dominio+macroarea','Output3','Metadati relativi all\'individuazione degli effetti causali','Individuazione della variabile da considerare come effetti casuali','report con lista variabili','Dati indagine formattati+flag dominio+macroarea+effetti casuali','Output3b','','','','Pacchetto R mind','Stima piccole aree','','FUA e city',57),('5.7 “Calculate aggregates”','Parametrizzazione del modello','Analisi dati','scelta macroarea (ad esempio modello per regione)','','Dati indagine formattati+flag dominio+macroarea+effetti casuali','Output3b','','Regressioni per l\'individuazione del modello con il miglior fitting','report','Tabelle di riassunto dei principali indicatori di model fitting (es AIC, BIC, loglk ecc)','Output9','','','','Pacchetto R mind','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Parametrizzazione del modello','Analisi dati','scelta metodo di stima parametri modello di regressione (OLS vs WLS)','','Dati indagine formattati+flag dominio+macroarea+effetti casuali','Output3b','Indicazione del peso (opzionale)','Individuazione della variabile peso campionario','report','Dati indagine formattati+flag dominio+macroarea+effetti casuali+peso','Output3c','','','','Pacchetto R mind','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','calcolo stime','Calcolo Stime','Calcolo Stime, indicatori di qualità delle stime e del modello','','Dati indagine formattati+flag dominio+macroarea+effetti casuali+peso\ne\nDataset di totali noti \n','Output3c+output4','\nparametri su cui sono possibili scelte alternative da parte del committente o della persona incaricata del calcolo','lancio della funzione R mind.unit ','lista con contenuti procedura di stima','Lista contenente output della funzione mind.unit','Output10','EBLUP, Projection e stimatore sintetico, OLS, WLS','','','Pacchetto R mind','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi dell\'output','valutazione modello','valutazione della qualità delle stime e del modello, ovvero valutazione  di MSE,CV, ICC, random effects, beta, standard deviation residui, standard deviatione ffetti casuali, ecc','','ouput passo di stima','','indicazioni sulla qualità accettabile','','report','','','REML, Intraclass Correlation Coefficent,R2, Adj R2,…','','','Pacchetto R mind','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi dell\'output','analisi distribuzioni','Analisi delle distribuzioni delle stime e dei CV\n','','Lista contenente output della funzione mind.unit e Dataset di stime dirette (calibrate) e cv per dominio','Output10 e Output5','Indicazione da parte dei committenti in merito alla qualità minima accettabile dell\'accuratezza delle stime espresse in termini di CV per ciascun dominio (spesso provenienti da regolamenti Europei e linee guida internazionali)','Confronto tra stime dirette ed indirette','report','Tabelle che indicano quanti e quali domini non soddisfano i criteri di accettabilità indicati dai committenti','Output11','boxplot, istogrammi, quartili, plot, tabelle differenze, ecc.','','','Pacchetto R mind','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi dell\'output','analisi distribuzioni','diagnostica stime da modello','','Output10 e Output5','','','lancio funzione diagnostic.R','report','Lista contenente output della funzione diagnostic.R','Output14','Bias diagnostic, coverage diagnostic, goodness of fit diagnostic, calibration diagnostic','','','Funzione diagnostic.R','Stima piccole aree','','',57),('5.7 “Calculate aggregates”','Analisi dell\'output','analisi spaziale','Analisi spaziale delle stime serve ad identificare eventuali pattern spaziali delle stime tipicamente attraverso la mappatura delle stime e degli errori per individuazioni di eventuali patter spaziali','','Lista contenente output della funzione mind.unit e Dataset di stime dirette (calibrate) e cv per dominio e shapefile di dominio','Output10 +  Output5+shapefile','conoscenza del fenomeno e del territorio di supporto alla ricerca dei pattern','spatial analysis ','report','Mappe per stime e cv','Output13','','','','','Stima piccole aree','','',57),('5.1 Integrate data','Acquisizione delle fonti da integrare','lettura dati','lettura prima fonte ','I dati del dataset relativo alla prima fonte vengono caricati assieme ai nomi delle variabili presenti','primo archivio o fonte  da integrare','input1','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','dataset in memoria','i dati dalla fonte 1 sono desponibili per il processo di elaborazione','output 1','','','','','Integrazione dati','','',51),('5.1 Integrate data','Acquisizione delle fonti da integrare','lettura dati','lettura seconda fonte','I dati del dataset relativo alla seconda fonte vengono caricati assieme ai nomi delle variabili presenti','Secondo archivio o fonte  da integrare','input2','metadati di lettura (path, tracciato record, psw, ecc)','lettura dati (read, read.table, ecc)','dataset in memoria','i dati dalla fonte 2 sono desponibili per il processo di elaborazione','output 2','','','','','Integrazione dati','','',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Completezza','Calcolare l\'indice di completezza di una variabile','Quest\'indicatore, relativo ad una variabile di un dataset, rappresenta la frequenza con cui la variabile assuma un valore non missing nel dataset. Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ','Dataset caricati, elenco delle variabili','output 1 + output 2','','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Frazione di righe/unità senza missing value','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Accuratezza','Calcolare l\'indice di accuratezza di una variabile rispetto ad un dominio di valori','Quest\'indicatore, relativo ad una variabile di un dataset, rappresenta la frequenza con cui la variabile assuma un valore ammissibile nel dataset. Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ','Dataset caricati, elenco delle variabili','output 1 + output 2','Elenco valori ammissibili per la variabile','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Dato un elenco di valori corretti per la variabile, il valore dell\'indicatore é Frazione di righe/unità con un valore corretto','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Consistenza','Calcolare l\'indice di accuratezza di una variabile rispetto al valore si un\'altra variabile','Quest\'indicatore, relativo ad una variabile di un dataset, rappresenta la frequenza con cui la variabile nel dataset assuma un valore coerente con il valore di un\'altra variabile correlata. Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ','Dataset caricati, elenco delle variabili','output 1 + output 2','Nome variabili correlate, Elenco valori ammissibili per la variabile in relazione ai valori della variabile correlata','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Questo indicatore valuta se i valori di due variabile di una stessa riga/entità sono coerenti tra loro attraverso un elenco vi valori abbinati correttamente. Il valore é dell\'indicatore è la Frazione di righe/unità che hanno valori coerenti sulle due variabili','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Entropia','Calcolare la distribuzione dei valori della variabile nel dataset','Quest\'indicatore, relativo ad una variabile di un dataset, rappresenta la distribuzione di frequenza delle singole modalità che assume la variabile. Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ','Dataset caricati, elenco delle variabili','output 1 + output 2','','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Indice di Gini calcolato sulle frequenze delle modalità','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Correlazione tra variabili','Calcolare l\'indice di correlazione tra due variabile di un dataset','Quest\'indicatore, relativo ad due variabile di un dataset, rappresenta la frequenza con cui il valore di una delle due variabili dipende dal valore della seconda. Se il valore dell\'indicatore è alto (vicino a 1) è preferire non usare entrambe le variabili nel processo di integrazione','Dataset caricati, elenco delle coppie di variabili','output 1 + output 2','','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni coppia di variabili esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Indice di correlazione','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore di correlazione con le altre variabili è basso (vicino a 0)  ',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Categorie','Calcolare il numero di modalità che assume la variabile di un dataset','Calcolare il numero di modalità che assume la variabile di un dataset','Dataset caricati, elenco delle variabili','output 1 + output 2','','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore intero','outputA1','V di Cramer','','','','Integrazione dati','','',51),('5.1 Integrate data','Analisi qualitativa delle variabili','Adeguatezza al bloccaggio','Calcolare per una variabile un indice di adeguatezza ad essere usata com variabile di bloccaggio','Quest\'indicatore, relativo ad una variabile comune dei due dataset, valuta tutte le modalità che assume la variabile e la dimensione del blocco che ne risulterebbe se venisse usata come variabile di bloccaggio. Il valore dell\'indicatore é la frequenza delle modalità che generano blocchi di dimensione nel range previsto. Le variabili più adeguate sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ','Dataset caricati, elenco delle variabili','output 1 + output 2','Range sulla dimensione del singolo blocco','Calcolo indice sintetico','Tabella con il valore dell\'indicatore per ogni variabile esaminata','Per ogni variabile esaminata l\'indicatore assume un valore numerico decimale compreso tra 0 e 1, è possibile dunque creare una gerarchia tra le variabili','outputA1','Simula la riduzione dello spazio di ricerca per bloccaggio calcolando il numero di blocchi e il numero di coppie in ogni blocco. Il valore dell\'indicatore è la Frazione di blocchi con un numero di coppie nel range definito','','','','Integrazione dati','',' Le variabili migliori sono quelle per cui il valore dell\'indicatore è alto (vicino a 1)  ',51),('5.1 Integrate data','preparazione dati','Lista dei valori inaccurati','Elenco delle modalità di una variabile non conformi al formato atteso','Se alcune variabili comuni possono essere considerate utili per il processo di integrazione ma sono rappresentate nelle due fonti con strutture differenti si applicano delle tecniche di trasformazione per renderle meglio confrontabili con gli algoritmi di confronto standard','Dataset da integrare','output 1 + output 2','formato previsto per i valori della variabile','Tutti i valori della variabile non conformi al formato previsto sono inseriti in una lista di valori inaccurati','file con la lista dei valori inaccurati','lista dei valori inaccurati','outputA2','','','','','Integrazione dati','','',51),('5.1 Integrate data','preparazione dati','Standardizzazione','Aggiunta di nuove variabili ai dataset attraverso trasformazioni delle variabili esistenti','','','','tipo di standardizzazione','La nuova variabile si ottiene applicando alla vecchia alcune semplici operazioni di standardizzazione come il cambio dal case o la cancellazione di alcuni caratteri speciali','dataset modificati','Dataset da integrare','output 1 + output 2','','','','','Integrazione dati','','',51),('5.1 Integrate data','preparazione dati','Fusione','','','','','eventuale carattere di separazione','La nuova variabile si ottiene concatenando i valori di due o più variabili','dataset modificati','Dataset da integrare','output 1 + output 2','','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','preparazione dati','Separazione','','','','','carattere separatore','Due nuove variabili si ottengono spezzando il valore di una variabile','dataset modificati','Dataset da integrare','output 1 + output 2','','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','preparazione dati','Risoluzione degli errori','','','','','lista di valori errati con correzione','La nuova variabile si ottiene sostituendo i valori definiti errati nella lista di sipporto col corrispondente valore corretto','dataset modificati','Dataset da integrare','output 1 + output 2','','','','','Integrazione dati','','',51),('5.1 Integrate data','preparazione dati','Riconciliazione degli schemi','Individuazione delle variabili comuni nei due dataset','','','','','Due variabili dei due dataset possono essere indicante come associate anche se hanno un  nome diverso','','','','','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','Prodotto cartesiano','Si selezionano le coppie di record su cui sarà eseguito il modello decisionale','Si tratta di un passo fondamentale nel processo di integrazione e deve conciliare la richiesta di alta qualità del risultato con la necessità  di rendere trattabile il problema dal puntoi di vista computazionale. In questo passo si decidono con una tecnica efficiente le sole coppie di record (dei due dataset) che saranno oggetto del processo nei passi successivi. Solo le coppie presenti nello spazio di ricerca potranno essere dichiarate match ovvero risultare abbinati alla fine del processo di integrazione.','Dataset da integrare','output 1 + output 2','','Lo spazio di ricerca è composto da tutte le possibili coppie','Spazio di ricerca',' ','output3','Cross Product','','','fastLink; Rlfunc','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','Bloccaggio','','','','','Variabili di bloccaggio','Lo spazio di ricerca è composto da tutte le coppie che hanno lo stesso valore sulle variabili di bloccaggio. Ogni modalità crea un blocco distinto','','','','Blocking','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','Unione di bloccaggi','','','','','Variabili di bloccaggio','Lo spazio di ricerca è composto da tutte le coppie che hanno lo stesso valore sulle variabili di bloccaggio. Viene creato un unico insieme','','','','Blocking','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','Vicini ordinati','','','','','Variabili di ordinamento e dimensione della finestra','Lo spazio di ricerca è composto da tutte le coppie che sono sufficientemente vicine (all\'interno di una stessa finestra) nell\'ordinameno','','','','Sorted Neighborhood','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','Bloccaggio innestato','','','','','Variabili di bloccaggio, variabili di ordinamento e dimensione della finestra','Si considerano solo le coppie che hanno lo stesso valore sulle variabili di bloccaggio. All\'interno di ogni blocco si scelgono solo le coppie che sono sufficientemente vicine (all\'interno di una stessa finestra) nell\'ordinameno sulle variabili di ordinamento e queste compongono lo spazio di ricerca','','','','Blocking + Sorted Neighborhood','','','','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','SimHash','','','','','Variabili di hashing, dimensione del q-gramma, numero di rotazioni, soglia sulla distanza degli hash','Per ogni record viene creata un\'impronta hash di lunghezza fissa che poi viene usata per ordinare i dataset. Per i record vicini vengono confrontate le impronte se la distanza di Hamming è inferiore alla soglia la coppia entra nello spazio di ricerca. L\'operazione si può replicare più volte permutando i bit dell\'impronta','','','','SimHash','','','','Integrazione dati','','',51),('5.1 Integrate data','Creazione dello spazio di ricerca','SimHash bloccato','','','','','Variabili di bloccaggio, variabili di hashing, dimensione del q-gramma, numero di rotazioni, soglia sulla distanza degli hash','Si considerano solo le coppie che hanno lo stesso valore sulle variabili di bloccaggio. All\'interno di ogni blocco si applica poi il metodo SimHash per scegliere le coppie che compongono lo spazio di ricerca','','','','Blocking + SimHash','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Uguaglianza','Scelta delle variabili di matching scelta delle metriche di confronto e delle soglie','In base alle indicazioni del committente o, in mancanza di queste, in base agli indicatori di qualità calcolati sulle variabili comuni (output3) si seleziona un set di variabili definito variabili di matching. Questo set è un sottoinsieme delle variabili comuni che devono assicurare un buon livello di completezza e di potere identificativo delle entità oggetto di integrazione. Per ogni variabile si decide un algoritmo di confronto. Il confronto può essere esatto (usuaglianza) o approssimato (similitudine). In caso si scelga un algoritmo approssimato va anche definita una soglia oltre la quale i due valori sono considerati concordanti e sotto la quale sono considerati discordanti.','Spazio di ricerca, Variabili di matching, funzioni di confronto e soglie','output3','','Confronto i record di ogni coppia su tutte le vatriabili di matching e associo la coppia ad un profilo che è un vettore di 0 e 1. Se nel posto i del vettore c\'è uno 0 vuol dire che la coppia è discordante sulla variabile i, se c\'è un 1 vuol dire che è concordante.','Tabella di contingenza','Le tabella di contingenza contiene tutti i possibili profili, ovvero tutte le possibili combinazioni di 0 e 1 (discordanze e concordanze) sulle variabili di matching. Per ogni profilo è indicato il numero di coppie dello spazio di ricerca che hanno quel profilo','output4','Uguaglianza','','','fastLink; Rlfunc','Integrazione dati','','Se diversi profili (righe) della tabella di contingenza hanno una frequenza 0 o comunque molto bassa rispetto alle dimensioni dei dataset vuol dire che c\'è qualche variabile con basso potere identificativo o correlata con le altre variabili, in questo caso sarà necessario rieseguire il passo cambiando le variabili di matching o modificando le funzioni e le soglie scelte.',51),('5.1 Integrate data','Confronto','Somiglianza di Levensthein','','','','','','','','','','Somiglianza di Levensthein','','','fastLink; Rlfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza di Jaro','','','','','','','','','','Somiglianza di Jaro','','','fastLink','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza di Jaro-Winkler','','','','','','','','','','Somiglianza di Jaro-Winkler','','','fastLink; Rlfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza Soundex','','','','','','','','','','Somiglianza Soundex','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza Q-Grams','','','','','','','','','','Somiglianza Q-Grams','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza inclusion 3-Grams','','','','','','','','','','Somiglianza Q-Grams con target la stringa più piccola','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza 3-Grams pesata','','','','','','','','','','Somiglianza Q-Grams con i pesi TF*IDF','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza SimHash','','','','','','','','','','SimHash','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza numerica','','','','','','','','','','Somiglianza numerica','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza uguaglianza con tolleranza','','','','','','','','','','Uguaglianza numerica con tolleranza','','','','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza di Dice','','','','','','','','','','Somiglianza di Dice','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza Full Damerau-Levenshtein','','','','','','','','','','Somiglianza Full Damerau-Levenshtein','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza Hamming','','','','','','','','','','Somiglianza Hamming','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Somiglianza per maggior sottostringa comune','','','','','','','','','','Somiglianza per maggior sottostringa comune','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Distanza coseno tra profili Q-Grams','','','','','','','','','','Q-Grams con Distanza coseno','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Confronto','Distanza di Jaccard tra profili Q-Grams','','','','','','','','','','Q-Grams con Distanza di Jaccard','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Modello decisionale','Deterministico esatto','Il modello individua i profili delle coppie da considerare match','Nel modello deterministico esatto i match sono solo le coppie che hanno concordanza su tutte le variabili di matching','tabella di contingenza','output4','','Il profilo dei match è solo quello con tutte le concordanze (vettore di tutti 1)','Tabella MU',' Tabella con tutti i profili divisi in match/unmatch','output5','Merge','','','RLfunc','Integrazione dati','','Se le probabilità marginali risultano incoerenti ( le concordanze sono più frequenti in U o le discordanze sono più frequenti in M) è necessario cambiare i parametri del modello perché il fenomeno descritto non è quello desiderato. In questo caso sarà necessario rieseguire i passi di confronto e modello decisionale cambiando le variabili di matching o modificando le funzioni e le soglie scelte per il confronto.',51),('5.1 Integrate data','Modello decisionale','Deterministico basato su regola','In base alla regola scelta il modello individua i profili delle coppie da considerare match','I match sono tutte le coppie che in base alla concordanza/discordanza sulle variabili di matching verificano la regola','','','Regola definita su concordanza e discordanza sulle variabili di matching','I profili dei match sono quelli che verificano la regola','Tabella MU',' Tabella con tutti i profili divisi in match/unmatch','output5','Verifica deterministica dei profili','','','RLfunc','Integrazione dati','','',51),('5.1 Integrate data','Modello decisionale','Probabilistico di Fellegi-Sunter','Il modello probabilistico assegna ad ogni coppie una probabilità a posteriori di essere un match','Per i modelli deterministici bisogna individuare i profili delle coppie da considerare match e questo deve essere fatto sulla base delle distribuzioni di frequenza della tabella di contingenza e in base alle indicazioni del commitente. Per i modelli probabilistici sarà il modello stesso autonomamente a classificare i profili assegnando ad ognuno una probabilità a posteriori','','','','Prima si stimano le probabilita marginali delle singole variabili di matching in caso di concordanza (m1 e u1) e in caso di discordanza (m0 e u0). Ad ogni profilo viene associata una probabilita m e u queste si calcolano come il prodotto delle probabilita marginali m1 e u1 delle singole variabili che valgono 1 sul profilo e mo e u0 per le variabili che valgono 0 sul profilo','Tabella delle probabilita marginali delle variabili di matching e MU table ','Tabella riportante le probabilità marginali stimate dal modello per ogni variabile di matching in caso di concordanza (m1, u1) e discordanza (m0,u0). Tabella con la probabilità a posteriori per ogni profilo calcolata dalle probabilità marginali ','output5 + output6','Algoritmo EM per la stima delle marginali, formula della probabilità condizionata per calcola la probabilità a posteriori','','','fastLink; Rlfunc','Integrazione dati','','',51),('5.1 Integrate data','Modello decisionale','Probabilistico da Marginali','In base alle probabilità marginali inserite il modello probabilistico assegna ad ogni coppie una probabilità a posteriori di essere un match','Sfruttando le probabilità marginali di ogni singola variabile di matching e utilizzando l\'ipotesi di indipendenza condizionata di queste viene calcolata la probabilità a posteriori che dipende solo dal priofilo','','','Probabilita marginali m1, u1 e m0, u0  per tutte variabili di matching','Ad ogni profilo viene associata una probabilita m e u queste si calcolano come il prodotto delle probabilita marginali m1 e u1 delle singole variabili che valgono 1 sul profilo e mo e u0 per le variabili che valgono 0 sul profilo','MU table','Tabella con la probabilità a posteriori per ogni profilo calcolata dalle probabilità marginali ','output5','Algoritmo EM per la stima delle marginali, formula della probabilità condizionata per calcola la probabilità a posteriori','','','fastLink','Integrazione dati','','',51),('5.1 Integrate data','Abbinamento dei record','Abbinamento dei record','Scelta delle soglie (per i modelli probabilistici) e inferenza dello stato di abbinamento sui record dei dataset','Se il modello è probabilistico si scelgono due soglie: soglia di match e soglia di unmatch. Tutti i profili con una probabilita a posteriori maggiore della soglia di match sono classificati come match (abbinamenti), i profili con una probabilità inferiore alla soglia di unmatch sono classificati come unmatch (non abbinamenti), i profili con una probabilità compresa tra le due soglie sono classificati come possible match (ossia devono essere revisionati ulteriormente). Una volta classificati tutti i profili lo status (match/unmatch/possible Match) viene inferito dai profili a tutte le coppie di record che fanno parte di quel profilo e vengono dunque create le liste degli abbinamenti e delle eventuali coppie da revisionare.',' ','output1 +  output2 + output5',' ','Crea le liste degli abbinamenti, delle coppie da revisionare (se presenti) e degli indicatori di qualità sull\'abbinamento','Lista dei Match e dei PossibleMatch','Tabella dei i record abbinati con tutte le variabili comuni + Tabella dei record abbinati come coppie da revisionare con tutte le variabili comuni + Precision e recall calcolati dal modello per il risultato dell\'integrazione','output7 + output8 + output9','','','','','Integrazione dati','','Se il numero degli abbinamenti e delle coppie da revisionare è soddisfacente il processo di abbinamento si conclude se invece si ritiene insufficiente va eseguito un nuovo processo che riceve come input i record residui (non abbinati) delle due fonti.',51),('5.1 Integrate data','Applicazione del vincolo di 1:1','Riduzione Ottima','Nel caso sia richiesto si riduce la lista degli abbinamenti applicando il vincolo di abbinamento 1:1','In base alle indicazioni del committente si decide se l\'abbinamento dei record deve essere di tipo 1:1 ovvero se ogni record della prima fonte si deve abbinare al massimo ad un record della seconda fonte e viceversa. In questo caso si risolvono i casi di abbinamenti multipli scegliendo l\'abbinamento più promettente. La lista degli abbinamenti ridotti sarà un sottoinsieme della lista degli abbinamenti e più precisamente sarà quello con una qualità migliore tra tutti i sotto insiemi che verificano il vincolo.','Tabella match + Tabella dei possible match','output 7 + output8','','Data la funzione F che ha come dominio le coppie di abbinati ed é definita come la somma delle probabilità a posteriori delle coppie, il metodo individua il sotto insieme di record della tabella degli abbinati che, verificando il vincolo di unicità 1 a 1, massimizza F','Lista dei Match 1:1 e dei PossibleMatch 1:1','Tabella dei record abbinati che verificano il vincolo di 1:1 +  Tabella dei record abbinati come coppie da revisionareche verificano il vincolo di 1:1','output10 + output11','metodo del simplesso','','','fastLink','Integrazione dati','','Se il numero degli abbinamenti e delle coppie da revisionare è soddisfacente il processo di abbinamento si conclude se invece si ritiene insufficiente va eseguito un nuovo processo che riceve come input i record residui (non abbinati) delle due fonti.',51),('5.1 Integrate data','Applicazione del vincolo di 1:1','Riduzione metodo di Karmarcar','','','','','','Data la funzione F che ha come dominio le coppie di abbinati ed é definita come la somma delle probabilità a posteriori delle coppie, il metodo individua il sotto insieme di record della tabella degli abbinati che, verificando il vincolo di unicità 1 a 1, massimizza F','','','','metodo di Karmarkar','','','','Integrazione dati','','',51),('5.1 Integrate data','Applicazione del vincolo di 1:1','Riduzione greedy','','','','','','Si crea la lista di record della tabella degli abbinati ordinata per probabilità a posteriori e la coppia sopravvive alla riduzione solo se non viola il vincolo di unicità 1 a 1 con le altre coppie sopravvisute','','','','lista ordinata','','','RLfunc','Integrazione dati','','',51);

-- truncate csm_business_process;
-- truncate csm_business_function;
-- truncate csm_process_step;
-- truncate csm_business_service;
-- truncate csm_app_role;

INSERT INTO csm_business_service (ID, NAME, DESCR) VALUES	(999,'Dummy','Placeholder for undefined processes and objects') ;
INSERT INTO csm_app_role (ID, NAME, CODE, DESCR, ORDER_CODE, CLS_DATA_TYPE_ID,PARAMETER_ID) VALUES (999,'UNDEFINED','U','UNDEFINED VARIABLE',100,1,NULL);

-- inserimento oggetti processo
insert into csm_business_process (name) select distinct business_process from csm_excel_import where business_process is not null;
insert into csm_business_function (name) select distinct business_function from csm_excel_import where business_function is not null;
insert into csm_process_step (name, business_service_id) select distinct process_step, 1 from csm_excel_import where process_step is not null;


-- link oggetti processo
select distinct A.ID, A.name, B.id, B.name from csm_excel_import C join csm_business_function A on A.name = C.business_function join csm_business_process B on B.name = C.business_process;
select distinct A.ID, A.name, B.id, B.name from csm_excel_import C join csm_process_step A on A.name = C.process_step join csm_business_process B on B.name = C.business_process;

-- truncate csm_link_gsbpm_business_function;
insert into csm_link_gsbpm_business_function (business_function_id, gsbpm_id) 
select distinct A.id, C.phase from csm_excel_import C join csm_business_function A on A.name = C.business_function ;

-- truncate csm_link_function_process;
insert into csm_link_function_process (business_function_id, business_process_id) 
select distinct A.ID, B.id from csm_excel_import C join csm_business_function A on A.name = C.business_function join csm_business_process B on B.name = C.business_process;

-- truncate csm_link_process_step;
insert into csm_link_process_step (process_step_id, business_process_id) 
select distinct A.ID, B.id from csm_excel_import C join csm_process_step A on A.name = C.process_step join csm_business_process B on B.name = C.business_process;

-- ricostruzione process tree
create or replace view cms_view_process_tree as 
SELECT
  concat(csm_GSBPM_PROCESS.phase,'.', csm_GSBPM_PROCESS.subprocess) as gsbpm,
  csm_GSBPM_PROCESS.NAME as subprocess,
  csm_business_function.NAME AS `Business_Function`,
  csm_business_function.DESCR AS Funct_desc,
  csm_business_process.NAME AS Process,
  csm_business_process.DESCR AS Process_desc,
  csm_process_step.NAME AS Step,
  csm_process_step.DESCR AS Step_desc  
FROM csm_GSBPM_PROCESS
  inner JOIN csm_link_gsbpm_business_function
    ON csm_GSBPM_PROCESS.ID = csm_link_gsbpm_business_function.gsbpm_ID
  inner JOIN csm_business_function
    ON csm_link_gsbpm_business_function.business_function_ID = csm_business_function.ID
  inner JOIN csm_link_function_process
    ON csm_link_function_process.BUSINESS_FUNCTION_ID = csm_business_function.ID
  INNER JOIN csm_business_process
    ON csm_link_function_process.BUSINESS_PROCESS_ID = csm_business_process.ID
  INNER JOIN csm_link_process_step
    ON csm_link_process_step.BUSINESS_PROCESS_ID = csm_business_process.ID
  INNER JOIN csm_process_step
    ON csm_link_process_step.PROCESS_STEP_ID = csm_process_step.ID;
    
-- set information objects
-- non può essere usata in una view per via della parametrizzazione. Va spezzata in due
select distinct descr, name, type, step, process, (@row_number:=@row_number + 1) AS num, 999 as approle, 999 as service 
from 
( 
  (select trim(transormable_input) as descr, trim(label_in) as name, 1 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(label_in) != ''
    union 
    select trim(transformable_output) as descr, trim(label_out) as name, 2 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(label_out) != ''
    union
    select trim(process_support) as descr, 'SUPPORT'  as name, 3 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(process_support) != ''
   ) as X, (SELECT @row_number:=0) as Y
) ;

-- parte uno- UNION
create or replace view csm_excel_objects as 
select trim(transormable_input) as descr, trim(label_in) as name, 1 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(label_in) != ''
    union 
    select trim(transformable_output) as descr, trim(label_out) as name, 2 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(label_out) != ''
    union
    select trim(process_support) as descr, 'SUPPORT'  as name, 3 as type, process_step as step, business_process as process
    from 
    csm_excel_import where trim(process_support) != '';


-- truncate csm_information_object;
insert into csm_information_object  (id , name, descr, csm_app_role_ID, csm_business_service_ID)
select distinct (@row_number:=@row_number + 1) AS num, name, descr, 1 as approle, 1 as service -- type, step, process, 
from 
( 
 csm_excel_objects as X, (SELECT @row_number:=0) as Y
) ;

-- process design
-- truncate csm_process_design;
insert into csm_process_design (id, step, type, csm_information_object_id)
-- select distinct P.name as process, P.id as process_id, S.name step, S.id as step_id, C.name as object, C.descr, concat(P.id,S.id) as id, B.type
select distinct  concat(P.id,S.id) as id, S.id,  B.type, C.id as obj_id 
from csm_excel_objects B  join csm_information_object C on (B.name = C.name and B.descr = C.descr) 
join csm_process_step S on (S.name = B.step)
join csm_business_process P on (P.name = B.process);
-- order by S.id, P.name;

create or replace view cms_view_process_design as
select distinct
P.id as process_id, 
P.name  process, 
S.id as step_id, 
S.name step, 
D.id as design_id,
D.name as design,
O.name as object, 
O.descr as description, 
D.type
from 
		 csm_process_design D  
    join csm_information_object O on (D.csm_information_object_id = O.id ) 
	join csm_process_step S on (S.id = D.step)
    join csm_link_process_step L on (S.id = L.PROCESS_STEP_ID)
	join csm_business_process P on (P.id = L.BUSINESS_PROCESS_ID)
order by D.id, S.id;


-- methodological tool
-- truncate csm_statistical_method;
insert into csm_statistical_method (name) 
select distinct process_method as tool FROM csm_excel_import where NULLIF(process_method, ' ') IS not NULL;

-- truncate csm_methodological_tool;
insert into csm_methodological_tool (name, tool_type, service) 
select distinct statistical_service as tool, 1 ttype, 1 service FROM csm_excel_import where NULLIF(statistical_service, ' ') IS not NULL
union select distinct desktop_application as tool, 2 ttype, 1 service FROM csm_excel_import where NULLIF(desktop_application, ' ') IS not NULL
union select distinct procname as tool, 3 ttype, 1 service FROM csm_excel_import where NULLIF(procname, ' ') IS not NULL;

-- truncate csm_link_method_tool;
insert into csm_link_method_tool (method, tool)
SELECT distinct  M.id, T.id
FROM csm_excel_import A join csm_statistical_method M on A.process_method = M.NAME  
join csm_methodological_tool T 
on (T.name = A.desktop_application or T.Name = A.statistical_service or T.name = A.procname);

create or replace view cms_view_methodological_tool as
SELECT DISTINCT
        g.CODE AS gsbpm_id,
        g.NAME AS gsbpm,
        t.ID AS tool_id,
        t.Name AS tool,
        t.Tool_type AS Tool_type,
        m.ID AS method_id,
        m.Name AS method,
        i.ID AS funct_id,
        i.method AS functionality
    FROM
             csm_GSBPM_PROCESS G
		JOIN csm_tool_gsbpm b ON b.gsbpm = g.ID
        JOIN csm_methodological_tool t ON (t.ID = b.tool)
		JOIN csm_link_method_tool a ON (t.ID = a.tool)
        JOIN csm_statistical_method m ON (a.method = m.ID)
        left JOIN csm_step_instance i ON (m.ID = i.STATMETHOD);

insert into csm_tool_gsbpm (tool, gsbpm)
SELECT distinct T.id tool, A.phase gsbpm -- , t.Tool_type, T.id
FROM csm_excel_import A join csm_methodological_tool T 
on (T.name = A.desktop_application or T.Name = A.statistical_service or T.name = A.procname);

select distinct name as tool from csm_methodological_tool order by name;

-- drop table csm_excel_import;
SET FOREIGN_KEY_CHECKS=1;
SET SQL_MODE=@OLD_SQL_MODE;
SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS;
SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS;
